{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6563f502",
            "metadata": {},
            "source": [
                "# **1. Perkenalan Dataset**\n",
                "\n",
                "**Nama Dataset**: Retail Transaction Data (Demand Forecasting)\n",
                "**Sumber**: [Kaggle - Retail Transaction Data](https://www.kaggle.com/datasets/mukuldeshantri/ecommerce-data)\n",
                "**Deskripsi Ringkas**: Dataset ini berisi transaksi penjualan historis yang mencakup informasi harga, unit terjual, dan tanggal. Tujuan utama eksperimen ini adalah memprediksi jumlah unit yang terjual (`units_sold`) di masa depan untuk keperluan manajemen inventaris (Demand Forecasting).\n",
                "\n",
                "Informasi Atribut:\n",
                "- `week`: Tanggal penjualan (mingguan)\n",
                "- `sku_id`: ID unik untuk setiap produk\n",
                "- `store_id`: ID unik untuk setiap toko\n",
                "- `base_price`: Harga dasar produk\n",
                "- `total_price`: Harga jual produk (termasuk diskon/promosi)\n",
                "- `units_sold`: Target variabel (jumlah unit yang terjual)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "090040c3",
            "metadata": {},
            "source": [
                "# **2. Import Library**\n",
                "Pada tahap ini, library yang dibutuhkan untuk pemrosesan data, visualisasi, dan pemodelan diimpor.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59c4cc86",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from category_encoders import MEstimateEncoder\n",
                "\n",
                "# Pastikan config.py ada di folder yang sama atau definisikan di sini\n",
                "try:\n",
                "    from config import SKU_SPECIFIC_LAGS, SKU_SPECIFIC_MAS\n",
                "except ImportError:\n",
                "    # Definisi fallback jika config.py tidak ditemukan\n",
                "    SKU_SPECIFIC_LAGS = {216418: [1, 2, 3]}\n",
                "    SKU_SPECIFIC_MAS = {216418: [2, 4]} \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a45fdaae",
            "metadata": {},
            "source": [
                "# **3. Memuat Dataset**\n",
                "Memuat dataset `train.csv` ke dalam DataFrame pandas.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca3ad0a6",
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    train = pd.read_csv('../data/train.csv') # Path relative menyesuaikan struktur folder\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "except FileNotFoundError:\n",
                "    # Fallback path\n",
                "    if os.path.exists('data/train.csv'):\n",
                "        train = pd.read_csv('data/train.csv')\n",
                "    else:\n",
                "        print(\"Error: train.csv not found.\")\n",
                "\n",
                "train.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0ab521c9",
            "metadata": {},
            "source": [
                "# **4. Exploratory Data Analysis (EDA)**\n",
                "Melihat struktur data, tipe data, missing values, dan statistik deskriptif.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "732ef7c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cek Info Data\n",
                "print(\"Data Info:\")\n",
                "print(train.info())\n",
                "\n",
                "# Cek Statistik Deskriptif\n",
                "print(\"\\nStatistik Deskriptif:\")\n",
                "print(train.describe())\n",
                "\n",
                "# Cek Missing Values\n",
                "print(\"\\nMissing Values:\")\n",
                "print(train.isnull().sum())\n",
                "\n",
                "# Cek Duplikasi\n",
                "print(f\"\\nJumlah Duplikat: {train.duplicated().sum()}\")\n",
                "\n",
                "# Visualisasi Outlier Sederhana (Boxplot units_sold)\n",
                "plt.figure(figsize=(8, 4))\n",
                "sns.boxplot(x=train['units_sold'])\n",
                "plt.title('Boxplot Units Sold')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a503a45c",
            "metadata": {},
            "source": [
                "# **5. Data Preprocessing**\n",
                "Tahapan pembersihan dan penyiapan data:\n",
                "1. Konversi Tipe Data (Date)\n",
                "2. Handling Missing Values\n",
                "3. Handling Duplicates\n",
                "4. Encoding (Target Encoding)\n",
                "5. Feature Engineering (Lags & Moving Averages)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee0573c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Mulai Preprocessing...\")\n",
                "\n",
                "# 1. Konversi Date & Fix Leap Year\n",
                "train['week'] = pd.to_datetime(train['week'], format='%d/%m/%y')\n",
                "train.loc[train['week'] >= '2012-03-06', 'week'] -= pd.Timedelta(days=1)\n",
                "\n",
                "# 2. Handling Missing Values (Total Price)\n",
                "train['total_price'] = train['total_price'].fillna(train['base_price'])\n",
                "print(\"Missing values in total_price filled.\")\n",
                "\n",
                "# 3. Handling Duplicates (Jika ada)\n",
                "initial_rows = len(train)\n",
                "train = train.drop_duplicates()\n",
                "print(f\"Duplicates dropped: {initial_rows - len(train)}\")\n",
                "\n",
                "# 4. Target Encoding\n",
                "print(\"Melakukan Target Encoding...\")\n",
                "encoder = MEstimateEncoder(cols=['store_id'])\n",
                "encoder.fit(train[['store_id']], train['units_sold'])\n",
                "\n",
                "# Simpan Encoder\n",
                "os.makedirs('model_artifacts', exist_ok=True)\n",
                "joblib.dump(encoder, 'model_artifacts/store_encoder.pkl')\n",
                "train['store_encoded'] = encoder.transform(train[['store_id']])\n",
                "\n",
                "# 5. Feature Engineering (Lags & MA)\n",
                "# Filter SKU sesuai eksperimen (untuk efisiensi)\n",
                "target_skus = list(SKU_SPECIFIC_LAGS.keys())\n",
                "train = train[train['sku_id'].isin(target_skus)].copy()\n",
                "\n",
                "print(\"Membuat Fitur Time Series...\")\n",
                "df_list = []\n",
                "for sku_id in target_skus:\n",
                "    df_sku = train[train['sku_id'] == sku_id].copy().sort_values('week')\n",
                "    \n",
                "    # Lag\n",
                "    lags = SKU_SPECIFIC_LAGS.get(sku_id, [1])\n",
                "    for lag in lags:\n",
                "        df_sku[f'lag_{lag}'] = df_sku['units_sold'].shift(lag)\n",
                "        \n",
                "    # Moving Average\n",
                "    mas = SKU_SPECIFIC_MAS.get(sku_id, [1])\n",
                "    for window in mas:\n",
                "        df_sku[f'ma_{window}'] = df_sku['units_sold'].rolling(window=window).mean().shift(1)\n",
                "        \n",
                "    df_list.append(df_sku)\n",
                "\n",
                "df_final = pd.concat(df_list)\n",
                "df_final = df_final.dropna()\n",
                "print(f\"Data final shape: {df_final.shape}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4d96a4c3",
            "metadata": {},
            "source": [
                "# **6. Simpan Hasil**\n",
                "Menyimpan data yang sudah diproses ke `train_processed.csv`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2fae9dc2",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('data/processed', exist_ok=True)\n",
                "output_path = 'data/processed/train_processed.csv'\n",
                "df_final.to_csv(output_path, index=False)\n",
                "print(f\"Data tersimpan di {output_path}\")\n"
            ]
        }
    ],
    "metadata": {},
    "nbformat": 4,
    "nbformat_minor": 5
}